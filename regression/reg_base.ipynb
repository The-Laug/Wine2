{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression, Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "from dtuimldmtools import similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pyplot import figure, legend, plot, show, xlabel, ylabel\n",
    "# exercise 8.1.1\n",
    "import torch\n",
    "import importlib_resources\n",
    "\n",
    "from matplotlib.pylab import (\n",
    "    figure,\n",
    "    grid,\n",
    "    legend,\n",
    "    loglog,\n",
    "    semilogx,\n",
    "    show,\n",
    "    subplot,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    ")\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "from dtuimldmtools import draw_neural_net, train_neural_net, rlr_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFFLINE LOADING OF DATA\n",
    "X = np.loadtxt('../wine/wine.data', delimiter=',')\n",
    "y = X[:,0]\n",
    "X = np.delete(X,0,axis=1)\n",
    "# y = np.loadtxt('./wine/wine.names', delimiter=',')\n",
    "\n",
    "Xorig = X\n",
    "# Standardizing the data\n",
    "\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# One of K encoding\n",
    "# y = similarity.one_of_k(y)\n",
    "\n",
    "# Ensure y values are within the range of the identity matrix's size\n",
    "num_classes = int(np.max(y)) + 1\n",
    "y2 = np.eye(num_classes)[y.astype(int)]\n",
    "\n",
    "#removing first column of y\n",
    "y2 = y2[:,1:]\n",
    "\n",
    "#Appending y to X\n",
    "X = np.append(X,y2,axis=1)\n",
    "\n",
    "#Extracting the first column of X\n",
    "y = X[:,0]\n",
    "\n",
    "\n",
    "\n",
    "attributeNames = [\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\"\n",
    "]\n",
    "\n",
    "#Removing the first column of X\n",
    "X = np.delete(X,0,axis=1)\n",
    "# Removing alcohol from attributenames\n",
    "attributeNames = attributeNames[1:]\n",
    "\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), 1)\n",
    "attributeNames = [\"Offset\"] + attributeNames + [\"Class 1\", \"Class 2\", \"Class 3\"]\n",
    "M = M + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1/10...\n",
      "     Fold 1/10 - MSE test: 1.1352\n",
      "Computing fold 2/10...\n",
      "     Fold 2/10 - MSE test: 1.1084\n",
      "Computing fold 3/10...\n",
      "     Fold 3/10 - MSE test: 0.6024\n",
      "Computing fold 4/10...\n",
      "     Fold 4/10 - MSE test: 1.1291\n",
      "Computing fold 5/10...\n",
      "     Fold 5/10 - MSE test: 0.8579\n",
      "Computing fold 6/10...\n",
      "     Fold 6/10 - MSE test: 1.4315\n",
      "Computing fold 7/10...\n",
      "     Fold 7/10 - MSE test: 1.2407\n",
      "Computing fold 8/10...\n",
      "     Fold 8/10 - MSE test: 0.8923\n",
      "Computing fold 9/10...\n",
      "     Fold 9/10 - MSE test: 0.7644\n",
      "Computing fold 10/10...\n",
      "     Fold 10/10 - MSE test: 0.8997\n",
      "\n",
      "Baseline Model Results:\n",
      "Average training MSE: 0.9996\n",
      "Average test MSE: 1.0062\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up K-Fold cross-validation (using outer loop)\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Initialize arrays to store errors for each fold\n",
    "baseline_errors_train = np.empty(K)\n",
    "baseline_errors_test = np.empty(K)\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    print(f\"Computing fold {k + 1}/{K}...\")\n",
    "\n",
    "    # Extract training and test sets for the current fold\n",
    "    X_train, y_train = X[train_index, :], y[train_index]\n",
    "    X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "    # Step 3: Baseline model - predict the mean of y_train\n",
    "    mean_y_train = np.mean(y_train)\n",
    "\n",
    "    # Predict the mean for both training and test sets\n",
    "    y_pred_train = np.full(len(y_train), mean_y_train)\n",
    "    y_pred_test = np.full(len(y_test), mean_y_train)\n",
    "\n",
    "    # Step 4: Calculate Mean Squared Error (MSE) for training and test sets\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    # Store the errors\n",
    "    baseline_errors_train[k] = mse_train\n",
    "    baseline_errors_test[k] = mse_test\n",
    "\n",
    "    print(f\"     Fold {k + 1}/{K} - MSE test: {mse_test:.4f}\")\n",
    "\n",
    "    k += 1\n",
    "\n",
    "# Step 5: Print the results\n",
    "print(\"\\nBaseline Model Results:\")\n",
    "print(f\"Average training MSE: {np.mean(baseline_errors_train):.4f}\")\n",
    "print(f\"Average test MSE: {np.mean(baseline_errors_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit ANN model - Do not use, friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CV fold 1/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.31674185\t0.00012662944\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.31674185\t0.00012662944\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24613397\t0.0003204611\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.24613397\t0.0003204611\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.29696822\t0.000315618\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.29696822\t0.000315618\n",
      "     Fold 1/10 - MSE test: 0.4216\n",
      "Computing CV fold 2/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.22796433\t0.00039446008\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.22796433\t0.00039446008\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.23435465\t0.00022020581\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.23435465\t0.00022020581\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26538295\t0.00022948712\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.26538295\t0.00022948712\n",
      "     Fold 2/10 - MSE test: 0.5688\n",
      "Computing CV fold 3/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.28784746\t0.00024179957\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.28784746\t0.00024179957\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.23437896\t0.0005356688\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.23437896\t0.0005356688\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.26394424\t0.0004192901\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.26394424\t0.0004192901\n",
      "     Fold 3/10 - MSE test: 0.5385\n",
      "Computing CV fold 4/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29168135\t0.0005190821\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.29168135\t0.0005190821\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.27669632\t0.00017574806\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.27669632\t0.00017574806\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24180993\t0.00014436289\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.24180993\t0.00014436289\n",
      "     Fold 4/10 - MSE test: 0.8577\n",
      "Computing CV fold 5/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29752475\t0.000109070555\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.29752475\t0.000109070555\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.29881448\t0.00053459394\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.29881448\t0.00053459394\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.23801532\t0.00014628856\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.23801532\t0.00014628856\n",
      "     Fold 5/10 - MSE test: 0.2384\n",
      "Computing CV fold 6/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24938293\t0.00025441957\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.24938293\t0.00025441957\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.26715606\t0.00024524704\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.26715606\t0.00024524704\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.24325423\t0.00021968261\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.24325423\t0.00021968261\n",
      "     Fold 6/10 - MSE test: 0.3838\n",
      "Computing CV fold 7/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.34026253\t0.00021489049\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.34026253\t0.00021489049\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.23743431\t0.0004907234\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.23743431\t0.0004907234\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.2574911\t0.00016976347\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.2574911\t0.00016976347\n",
      "     Fold 7/10 - MSE test: 0.4051\n",
      "Computing CV fold 8/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.3151803\t0.00040293162\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.3151803\t0.00040293162\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.22278455\t0.00024327198\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.22278455\t0.00024327198\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.21696997\t0.0004702948\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.21696997\t0.0004702948\n",
      "     Fold 8/10 - MSE test: 0.5374\n",
      "Computing CV fold 9/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25309876\t0.00024968493\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.25309876\t0.00024968493\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.25241092\t0.00019513271\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.25241092\t0.00019513271\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.2766381\t0.00025353298\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.2766381\t0.00025353298\n",
      "     Fold 9/10 - MSE test: 0.7563\n",
      "Computing CV fold 10/10...\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.26443398\t0.0004850608\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.26443398\t0.0004850608\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauge/Desktop/ML/MLenv/lib/python3.12/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t1000\t0.27130598\t0.00013794961\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.27130598\t0.00013794961\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.2894213\t0.00031129076\n",
      "\t\tFinal loss:\n",
      "\t\t1000\t0.2894213\t0.00031129076\n",
      "     Fold 10/10 - MSE test: 0.2774\n",
      "\n",
      "ANN Model Results (Regression):\n",
      "Average training MSE: 0.2402\n",
      "Average test MSE: 0.4985\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "# Using script from: ex8_3_1 with modifications\n",
    "\n",
    "# Define K-Fold cross-validation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Define the model structure for regression\n",
    "n_hidden_units = 5                            # Adjust as needed\n",
    "model = lambda: torch.nn.Sequential(\n",
    "    torch.nn.Linear(X.shape[1], n_hidden_units),    # Input layer to hidden layer\n",
    "    torch.nn.ReLU(),                                # Activation function\n",
    "    torch.nn.Linear(n_hidden_units, 1)              # Output layer with one output (regression)\n",
    ")\n",
    "\n",
    "# Use MSE loss function for regression\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize variables to store errors\n",
    "Error_train = np.empty(K)\n",
    "Error_test = np.empty(K)\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    print(f\"Computing CV fold {k + 1}/{K}...\")\n",
    "\n",
    "    # Extract training and test sets\n",
    "    X_train, y_train = X[train_index, :], y[train_index]\n",
    "    X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "    # Convert data to torch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "    # Train the neural network\n",
    "    net, _, _ = train_neural_net(\n",
    "        model,\n",
    "        loss_fn,\n",
    "        X=X_train_tensor,\n",
    "        y=y_train_tensor,\n",
    "        n_replicates=3,\n",
    "        max_iter = 1000\n",
    "    )\n",
    "\n",
    "    # Make predictions on the training and test sets\n",
    "    y_train_pred = net(X_train_tensor).detach().numpy().flatten()\n",
    "    y_test_pred = net(X_test_tensor).detach().numpy().flatten()\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    Error_train[k] = mean_squared_error(y_train, y_train_pred)\n",
    "    Error_test[k] = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"     Fold {k + 1}/{K} - MSE test: {Error_test[k]:.4f}\")\n",
    "\n",
    "    k += 1\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nANN Model Results (Regression):\")\n",
    "print(f\"Average training MSE: {np.mean(Error_train):.4f}\")\n",
    "print(f\"Average test MSE: {np.mean(Error_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
