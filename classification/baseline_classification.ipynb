{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline - classification - most common class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pyplot import figure, legend, plot, show, xlabel, ylabel\n",
    "\n",
    "# exercise 8.1.1\n",
    "import torch\n",
    "import importlib_resources\n",
    "\n",
    "from matplotlib.pylab import (\n",
    "    figure,\n",
    "    grid,\n",
    "    legend,\n",
    "    loglog,\n",
    "    semilogx,\n",
    "    show,\n",
    "    subplot,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    ")\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "from scipy import stats\n",
    "\n",
    "from dtuimldmtools import draw_neural_net, train_neural_net, rlr_validate, similarity\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFFLINE LOADING OF DATA\n",
    "X = np.loadtxt('../wine/wine.data', delimiter=',')\n",
    "\n",
    "# Standardizing the data\n",
    "X[:, 1:] = (X[:, 1:] - np.mean(X[:, 1:], axis=0)) / np.std(X[:, 1:], axis=0)\n",
    "\n",
    "attributeNames = [\n",
    "    \"Class\",\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\",\n",
    "]\n",
    "\n",
    "y = X[:, 0]\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Class   Alcohol  Malic acid       Ash  Alcalinity of ash  Magnesium  \\\n",
      "0  1.518613 -0.562250    0.232053 -1.169593           1.913905   0.808997   \n",
      "1  0.246290 -0.499413   -0.827996 -2.490847           0.018145   0.568648   \n",
      "2  0.196879  0.021231    1.109334 -0.268738           0.088358   0.808997   \n",
      "3  1.691550 -0.346811    0.487926 -0.809251           0.930918   2.491446   \n",
      "4  0.295700  0.227694    1.840403  0.451946           1.281985   0.808997   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0       1.034819   -0.659563              1.224884         0.251717   \n",
      "1       0.733629   -0.820719             -0.544721        -0.293321   \n",
      "2       1.215533   -0.498407              2.135968         0.269020   \n",
      "3       1.466525   -0.981875              1.032155         1.186068   \n",
      "4       0.663351    0.226796              0.401404        -0.319276   \n",
      "\n",
      "   Color intensity       Hue  OD280/OD315 of diluted wines  \n",
      "0         0.362177  1.847920                      1.013009  \n",
      "1         0.406051  1.113449                      0.965242  \n",
      "2         0.318304  0.788587                      1.395148  \n",
      "3        -0.427544  1.184071                      2.334574  \n",
      "4         0.362177  0.449601                     -0.037874  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert the NumPy array 'X' to a DataFrame with column names\n",
    "# Ensure attributeNames has the correct number of column names\n",
    "attributeNames_corrected = attributeNames[:X.shape[1]]\n",
    "df = pd.DataFrame(X, columns=attributeNames_corrected)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing CV fold: 1/10..\n",
      "    Top class:  2.0   Test error:  0.556\n",
      "Computing CV fold: 2/10..\n",
      "    Top class:  2.0   Test error:  0.722\n",
      "Computing CV fold: 3/10..\n",
      "    Top class:  2.0   Test error:  0.667\n",
      "Computing CV fold: 4/10..\n",
      "    Top class:  2.0   Test error:  0.556\n",
      "Computing CV fold: 5/10..\n",
      "    Top class:  2.0   Test error:  0.556\n",
      "Computing CV fold: 6/10..\n",
      "    Top class:  2.0   Test error:  0.611\n",
      "Computing CV fold: 7/10..\n",
      "    Top class:  2.0   Test error:  0.667\n",
      "Computing CV fold: 8/10..\n",
      "    Top class:  2.0   Test error:  0.444\n",
      "Computing CV fold: 9/10..\n",
      "    Top class:  2.0   Test error:  0.588\n",
      "Computing CV fold: 10/10..\n",
      "    Top class:  2.0   Test error:  0.647\n",
      "\n",
      "Average training error: 0.6011\n",
      "Average test error: 0.6013\n"
     ]
    }
   ],
   "source": [
    "# Baseline model: Predict the most common class in the training set\n",
    "# Define the number of folds\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "# Initialize variables to store errors\n",
    "Error_train = np.empty(K)\n",
    "Error_test = np.empty(K)\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    print(f\"Computing CV fold: {k + 1}/{K}..\")\n",
    "\n",
    "    # Extract training and test set for the current CV fold\n",
    "    X_train, y_train = X[train_index, :], y[train_index]\n",
    "    X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "    # Baseline model: Predict the most common class in the training set\n",
    "    most_common_class = Counter(y_train).most_common(1)[0][0]\n",
    "\n",
    "    # Predict the most common class for all test and train samples\n",
    "    y_est_train = np.full(len(y_train), most_common_class)\n",
    "    y_est_test = np.full(len(y_test), most_common_class)\n",
    "\n",
    "    # Evaluate misclassification rate for train and test sets\n",
    "    misclass_rate_train = np.sum(y_est_train != y_train) / len(y_train)\n",
    "    misclass_rate_test = np.sum(y_est_test != y_test) / len(y_test)\n",
    "\n",
    "    print(\"    Top class: \", most_common_class, \"  Test error: \", round(misclass_rate_test,3))\n",
    "\n",
    "    # Store the errors\n",
    "    Error_train[k] = misclass_rate_train\n",
    "    Error_test[k] = misclass_rate_test\n",
    "\n",
    "    k += 1\n",
    "\n",
    "\n",
    "# Print the mean and standard deviation of errors across folds\n",
    "print(f\"\\nAverage training error: {np.mean(Error_train):.4f}\")\n",
    "print(f\"Average test error: {np.mean(Error_test):.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
