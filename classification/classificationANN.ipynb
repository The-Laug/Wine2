{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "from dtuimldmtools import similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pyplot import figure, legend, plot, show, xlabel, ylabel\n",
    "# exercise 8.1.1\n",
    "from dtuimldmtools import dbplotf, train_neural_net, visualize_decision_boundary\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.pyplot import figure, show, title\n",
    "from scipy.io import loadmat\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import (\n",
    "    figure,\n",
    "    grid,\n",
    "    legend,\n",
    "    loglog,\n",
    "    semilogx,\n",
    "    show,\n",
    "    subplot,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    ")\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "\n",
    "from dtuimldmtools import rlr_validate\n",
    "\n",
    "# fetch dataset \n",
    "# wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = wine.data.features \n",
    "# y = wine.data.targets \n",
    "\n",
    "# totaldata= (wine.data)\n",
    "  \n",
    "# metadata \n",
    "# print(wine.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(wine.variables) \n",
    "\n",
    "# OFFLINE LOADING OF DATA\n",
    "X = np.loadtxt('../wine/wine.data', delimiter=',')\n",
    "\n",
    "#Extract classes from X\n",
    "y = X[:,0]\n",
    "X = np.delete(X,0,axis=1)\n",
    "# y = np.loadtxt('../wine/wine.names', delimiter=',')\n",
    "\n",
    "Xorig = X\n",
    "# Standardizing the data\n",
    "\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "attributeNames = [\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\"\n",
    "]\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "# Add offset attribute\n",
    "attributeNames = [\"Offset\"] + attributeNames\n",
    "# M = M + 1\n",
    "\n",
    "\n",
    "classNames = [\"1\", \"2\", \"3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56542885\t4.8804734e-05\n",
      "\t\t2000\t0.554151\t6.02334e-06\n",
      "\t\t3000\t0.55239207\t1.5106368e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3271\t0.5521899\t9.714797e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5665134\t5.0499748e-05\n",
      "\t\t2000\t0.55511487\t8.589809e-06\n",
      "\t\t3000\t0.5525609\t2.265261e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3437\t0.55217516\t9.715056e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5602251\t3.7342932e-05\n",
      "\t\t2000\t0.55324864\t3.878471e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2916\t0.5521601\t9.715321e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.57906866\t0.00037031478\n",
      "\t\t2000\t0.55329263\t5.170877e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2860\t0.55208737\t9.716601e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.63580906\t0.00017846079\n",
      "\t\t2000\t0.57859814\t4.4191747e-05\n",
      "\t\t3000\t0.5634915\t1.5443256e-05\n",
      "\t\t4000\t0.55769455\t6.8400723e-06\n",
      "\t\t5000\t0.5549543\t3.3295316e-06\n",
      "\t\t6000\t0.5535\t1.9383588e-06\n",
      "\t\tFinal loss:\n",
      "\t\t6865\t0.552765\t9.704689e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56207114\t4.464281e-05\n",
      "\t\t2000\t0.55346185\t4.4154435e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2994\t0.55216897\t9.715166e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5711602\t6.2401676e-05\n",
      "\t\t2000\t0.55551213\t1.9742212e-05\n",
      "\t\t3000\t0.552627\t2.1571336e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3405\t0.552256\t6.4757586e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56102854\t3.5164776e-05\n",
      "\t\t2000\t0.55360126\t4.521998e-06\n",
      "\t\t3000\t0.55224526\t1.4031071e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3034\t0.5522221\t9.714231e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56140196\t4.2041975e-05\n",
      "\t\t2000\t0.55345905\t4.307772e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2998\t0.5521995\t9.714629e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56220967\t3.954335e-05\n",
      "\t\t2000\t0.5537595\t5.0588824e-06\n",
      "\t\t3000\t0.5522579\t1.2951464e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3113\t0.55217844\t9.714998e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5709307\t9.9169294e-05\n",
      "\t\t2000\t0.55417275\t6.2382132e-06\n",
      "\t\t3000\t0.55239254\t1.5106355e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3174\t0.5522583\t9.713593e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56696665\t6.170692e-05\n",
      "\t\t2000\t0.55416167\t6.453452e-06\n",
      "\t\t3000\t0.55233794\t1.6186979e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3232\t0.55216706\t9.715199e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5748574\t9.351599e-05\n",
      "\t\t2000\t0.5543324\t7.3116535e-06\n",
      "\t\t3000\t0.5523819\t1.5106647e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3215\t0.5522138\t9.714377e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.60132927\t0.00012111178\n",
      "\t\t2000\t0.56675225\t2.5660525e-05\n",
      "\t\t3000\t0.5581454\t8.863535e-06\n",
      "\t\t4000\t0.5548853\t3.8670314e-06\n",
      "\t\t5000\t0.5533594\t1.8311374e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5640\t0.55279386\t9.704183e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5647618\t3.8309347e-05\n",
      "\t\t2000\t0.55617183\t7.608975e-06\n",
      "\t\t3000\t0.5534611\t2.6923522e-06\n",
      "\t\t4000\t0.55246913\t1.2946512e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4045\t0.55243933\t8.631477e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5656167\t5.100128e-05\n",
      "\t\t2000\t0.55428356\t6.3444995e-06\n",
      "\t\t3000\t0.5524398\t1.7262925e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3293\t0.55221474\t9.71436e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5617474\t4.0424668e-05\n",
      "\t\t2000\t0.55370677\t4.7364274e-06\n",
      "\t\t3000\t0.5522841\t1.2950849e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3116\t0.55220443\t9.714541e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.59524345\t0.00010783366\n",
      "\t\t2000\t0.5648568\t2.2475613e-05\n",
      "\t\t3000\t0.5573345\t7.593102e-06\n",
      "\t\t4000\t0.5544921\t3.4398001e-06\n",
      "\t\t5000\t0.553154\t1.8318174e-06\n",
      "\t\tFinal loss:\n",
      "\t\t5583\t0.55269104\t9.705989e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56142414\t4.119105e-05\n",
      "\t\t2000\t0.5535532\t4.5223906e-06\n",
      "\t\t3000\t0.5522232\t1.1872922e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3034\t0.5522007\t9.714607e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5603744\t4.190635e-05\n",
      "\t\t2000\t0.5530778\t3.448596e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2810\t0.55214775\t9.715538e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56991875\t7.362204e-05\n",
      "\t\t2000\t0.554798\t7.73525e-06\n",
      "\t\t3000\t0.5525876\t1.8336949e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3445\t0.5522207\t9.714255e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56134903\t3.9179282e-05\n",
      "\t\t2000\t0.5534975\t4.307473e-06\n",
      "\t\t3000\t0.55220497\t1.0793923e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3017\t0.55219394\t9.714726e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56029785\t3.5742498e-05\n",
      "\t\t2000\t0.55310285\t3.8794933e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2814\t0.5521449\t9.71559e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5639893\t5.7277448e-05\n",
      "\t\t2000\t0.55361927\t5.167826e-06\n",
      "\t\t3000\t0.5521993\t1.5111641e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3070\t0.552148\t9.715535e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 18\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5678968\t5.321028e-05\n",
      "\t\t2000\t0.55525255\t8.587679e-06\n",
      "\t\t3000\t0.5527767\t2.1565495e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3615\t0.55222696\t9.714145e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5663192\t7.545798e-05\n",
      "\t\t2000\t0.5539386\t5.5952482e-06\n",
      "\t\t3000\t0.55234265\t1.4028598e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3189\t0.55220866\t9.714468e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5651468\t4.83018e-05\n",
      "\t\t2000\t0.5547462\t6.8764257e-06\n",
      "\t\t3000\t0.5526894\t1.8333573e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3527\t0.55225194\t9.713706e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 17\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.56868935\t6.0786424e-05\n",
      "\t\t2000\t0.5564416\t7.391054e-06\n",
      "\t\t3000\t0.5539224\t2.797714e-06\n",
      "\t\t4000\t0.55238324\t2.9134133e-06\n",
      "\t\tFinal loss:\n",
      "\t\t4413\t0.5518878\t9.720114e-07\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5657865\t3.3394295e-05\n",
      "\t\t2000\t0.5533168\t3.985715e-06\n",
      "\t\tFinal loss:\n",
      "\t\t2911\t0.55218816\t9.714828e-07\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\t1000\t0.5728826\t8.353986e-05\n",
      "\t\t2000\t0.55574787\t8.901773e-06\n",
      "\t\t3000\t0.5536969\t1.9376694e-06\n",
      "\t\tFinal loss:\n",
      "\t\t3085\t0.55360955\t8.613232e-07\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 17\n",
      "Ran Exercise 8.3.1\n"
     ]
    }
   ],
   "source": [
    "# %% ANN classification\n",
    "\n",
    "\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "# Initialize variables\n",
    "# T = len(lambdas)\n",
    "Error_train = np.empty((K, 1))\n",
    "Error_test = np.empty((K, 1))\n",
    "Error_train_rlr = np.empty((K, 1))\n",
    "Error_test_rlr = np.empty((K, 1))\n",
    "Error_train_nofeatures = np.empty((K, 1))\n",
    "Error_test_nofeatures = np.empty((K, 1))\n",
    "w_rlr = np.empty((M, K))\n",
    "mu = np.empty((K, M - 1))\n",
    "sigma = np.empty((K, M - 1))\n",
    "w_noreg = np.empty((M, K))\n",
    "\n",
    "# Convert class labels to 0, 1, 2\n",
    "y = y - 1\n",
    "\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    Error_train_avg = []\n",
    "    Error_test_avg = []\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "\n",
    "\n",
    "    # Define the model structure\n",
    "    n_hidden_units = 5  # number of hidden units in the signle hidden layer\n",
    "    C = 3\n",
    "    model = lambda: torch.nn.Sequential(\n",
    "        torch.nn.Linear(M, n_hidden_units),  # M features to H hiden units\n",
    "        torch.nn.ReLU(),  # 1st transfer function\n",
    "        # Output layer:\n",
    "        # H hidden units to C classes\n",
    "        # the nodes and their activation before the transfer\n",
    "        # function is often referred to as logits/logit output\n",
    "        torch.nn.Linear(n_hidden_units, C),  # C logits\n",
    "        # To obtain normalised \"probabilities\" of each class\n",
    "        # we use the softmax-funtion along the \"class\" dimension\n",
    "        # (i.e. not the dimension describing observations)\n",
    "        torch.nn.Softmax(dim=1),  # final tranfer function, normalisation of logit output\n",
    "    )\n",
    "    # Since we're training a multiclass problem, we cannot use binary cross entropy,\n",
    "    # but instead use the general cross entropy loss:\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # Train the network:\n",
    "    # C = 3\n",
    "    net, _, _ = train_neural_net(\n",
    "        model,\n",
    "        loss_fn,\n",
    "        X=torch.tensor(X_train, dtype=torch.float),\n",
    "        y=torch.tensor(y_train, dtype=torch.long),\n",
    "        n_replicates=3,\n",
    "        max_iter=10000\n",
    "    )\n",
    "    # Determine probability of each class using trained network\n",
    "    softmax_logits = net(torch.tensor(X_test, dtype=torch.float))\n",
    "    # Get the estimated class as the class with highest probability (argmax on softmax_logits)\n",
    "    y_test_est = (torch.max(softmax_logits, dim=1)[1]).data.numpy()\n",
    "    # Determine errors\n",
    "    e = y_test_est != y_test\n",
    "    print(\n",
    "        \"Number of miss-classifications for ANN:\\n\\t {0} out of {1}\".format(sum(e), len(e))\n",
    "    )\n",
    "\n",
    "    predict = lambda x: (\n",
    "        torch.max(net(torch.tensor(x, dtype=torch.float)), dim=1)[1]\n",
    "    ).data.numpy()\n",
    "    # figure(1, figsize=(9, 9))\n",
    "    # visualize_decision_boundary(\n",
    "    #     predict, [X_train, X_test], [y_train, y_test], attributeNames, classNames\n",
    "    # )\n",
    "    # title(\"ANN decision boundaries\")\n",
    "\n",
    "# show()\n",
    "\n",
    "print(\"Ran Exercise 8.3.1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
